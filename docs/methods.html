<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>3 Methods | Uncertainty Validation</title>
  <meta name="description" content="A synthesis of SWOT uncertainty model validation using simulations on the Sacramento River.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="3 Methods | Uncertainty Validation" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A synthesis of SWOT uncertainty model validation using simulations on the Sacramento River." />
  <meta name="github-repo" content="markwh/swot-error" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Methods | Uncertainty Validation" />
  
  <meta name="twitter:description" content="A synthesis of SWOT uncertainty model validation using simulations on the Sacramento River." />
  

<meta name="author" content="Mark Hagemann">


<meta name="date" content="2019-05-03">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="introduction.html">
<link rel="next" href="results.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Abstract</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a></li>
<li class="chapter" data-level="3" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>3</b> Methods</a><ul>
<li class="chapter" data-level="3.1" data-path="methods.html"><a href="methods.html#swot-river-data-products"><i class="fa fa-check"></i><b>3.1</b> SWOT River Data Products</a></li>
<li class="chapter" data-level="3.2" data-path="methods.html"><a href="methods.html#datasets"><i class="fa fa-check"></i><b>3.2</b> Datasets</a></li>
<li class="chapter" data-level="3.3" data-path="methods.html"><a href="methods.html#error-scaling"><i class="fa fa-check"></i><b>3.3</b> Error scaling</a><ul>
<li class="chapter" data-level="3.3.1" data-path="methods.html"><a href="methods.html#error-decomposition"><i class="fa fa-check"></i><b>3.3.1</b> Error Decomposition</a></li>
<li class="chapter" data-level="3.3.2" data-path="methods.html"><a href="methods.html#assumptions-of-normality"><i class="fa fa-check"></i><b>3.3.2</b> Assumptions of Normality</a></li>
<li class="chapter" data-level="3.3.3" data-path="methods.html"><a href="methods.html#tests-for-validity-of-hatsigma_x"><i class="fa fa-check"></i><b>3.3.3</b> Tests for validity of <span class="math inline">\(\hat{\sigma}_{x}\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>4</b> Results</a><ul>
<li class="chapter" data-level="4.1" data-path="results.html"><a href="results.html#node-results"><i class="fa fa-check"></i><b>4.1</b> Node Results</a><ul>
<li class="chapter" data-level="4.1.1" data-path="results.html"><a href="results.html#hypothesis-tests"><i class="fa fa-check"></i><b>4.1.1</b> Hypothesis tests</a></li>
<li class="chapter" data-level="4.1.2" data-path="results.html"><a href="results.html#distribution-plots"><i class="fa fa-check"></i><b>4.1.2</b> Distribution plots</a></li>
<li class="chapter" data-level="4.1.3" data-path="results.html"><a href="results.html#tables"><i class="fa fa-check"></i><b>4.1.3</b> Tables</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="results.html"><a href="results.html#reach-results"><i class="fa fa-check"></i><b>4.2</b> Reach results</a></li>
<li class="chapter" data-level="4.3" data-path="results.html"><a href="results.html#part-2-factors-affecting-errors-and-uncertainty"><i class="fa fa-check"></i><b>4.3</b> Part 2: Factors affecting errors and uncertainty</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Uncertainty Validation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="methods" class="section level1">
<h1><span class="header-section-number">3</span> Methods</h1>
<div id="swot-river-data-products" class="section level2">
<h2><span class="header-section-number">3.1</span> SWOT River Data Products</h2>
<ul>
<li>SLC product, simulation thereof</li>
<li>Stages of processing, fields calculated
<ul>
<li>Pixel cloud</li>
<li>node assignment</li>
<li>reach aggregation
<ul>
<li>computation of slope</li>
</ul></li>
</ul></li>
<li>Prior database, uses
<ul>
<li>Required to assign pixels</li>
<li>Refinement of prior db</li>
</ul></li>
</ul>
</div>
<div id="datasets" class="section level2">
<h2><span class="header-section-number">3.2</span> Datasets</h2>
<p>The study area consists of 733 nodes in comprising 10 reaches in the Sacramento River between 38.92 and 39.75 degrees latitude. Two simulations of the SWOT single-look complex (SLC) were created using two different flow conditions; other simulation parameters including <span class="math inline">\(\sigma_0\)</span> for water and land, SWOT pass number, and smearing distance were held constand. The water and land <span class="math inline">\(\sigma_0\)</span> were selected so as to remove any impact of layover.</p>
<ul>
<li>Datasets come from simulation of SWOT SLC using hydrodynamic models forced by observed hydrologic conditions</li>
<li>Validation data come from GDEM</li>
<li>Simulated river is #### km section of Sacramento River</li>
<li>Passes of SWOT satellite</li>
</ul>
<table>
<thead>
<tr class="header">
<th align="right">pass</th>
<th align="right">n_nodes</th>
<th align="right">date</th>
<th align="right">flow</th>
<th align="right">flow_pctile</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">249</td>
<td align="right">698</td>
<td align="right">2009-02-20</td>
<td align="right">9224</td>
<td align="right">67.3</td>
</tr>
<tr class="even">
<td align="right">264</td>
<td align="right">447</td>
<td align="right">2009-01-10</td>
<td align="right">4513</td>
<td align="right">5.0</td>
</tr>
<tr class="odd">
<td align="right">527</td>
<td align="right">733</td>
<td align="right">2009-01-19</td>
<td align="right">4203</td>
<td align="right">2.6</td>
</tr>
</tbody>
</table>
<p><img src="_main_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<ul>
<li>Statistics about validation variables</li>
</ul>
<p><img src="_main_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p><img src="_main_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="error-scaling" class="section level2">
<h2><span class="header-section-number">3.3</span> Error scaling</h2>
<p>The different SWOT observations are reported with estimates of <span class="math inline">\(1 \sigma\)</span> uncertainty; the objective of uncertainty validation is to determine how accurately these uncertainty estimates match the behavior of empirical errors. In order to easily compare across a set of validation data with varying uncertainty estimates, we employ a simple transformation such that the mean and variance should be equal across all transformed validation data.</p>
<p>Consider an arbitrary measured variable (e.g. node height, reach width, pixel latitude), denoted <span class="math inline">\(x_{st}\)</span>, where <span class="math inline">\(s\)</span> indexes location (in <strong>s</strong>pace), and <span class="math inline">\(t\)</span> indexes <strong>t</strong>ime. Because <span class="math inline">\(x\)</span> is not precisely determined and has nonzero error, we can consider it a random variable. The corresponding true value, of which <span class="math inline">\(x\)</span> is an estimate, is denoted <span class="math inline">\(x^*\)</span>. The error, <span class="math inline">\(\epsilon\)</span>, is defined as <span class="math inline">\(\epsilon = x - x^*\)</span>. Because <span class="math inline">\(\epsilon\)</span> is a transformation of a random variable, it is itself a random variable. We denote the mean, variance, and standard deviation of <span class="math inline">\(\epsilon\)</span> as <span class="math inline">\(\mu_\epsilon\)</span>, <span class="math inline">\(\sigma^2_\epsilon\)</span>, and <span class="math inline">\(\sigma_\epsilon\)</span>, respectively, and similarly for other random variables.</p>
<p>The objective of this study is to validate the quantification of uncertainty, where uncertainty is expressed as an estimate of <span class="math inline">\(\sigma_x\)</span>. We denote this estimate <span class="math inline">\(\hat{\sigma}_x\)</span>, to distinguish it from the true value <span class="math inline">\(\sigma_x\)</span>. We perform this validation over a potentially large number of locations <span class="math inline">\(s\)</span> and times <span class="math inline">\(t\)</span> (although at present only a single time has been considered). The data for a given observed variable therefore consist of observations of <span class="math inline">\(x_{st}\)</span> and <span class="math inline">\(\hat{\sigma}_{st}\)</span>; these are both provided in the rivertile product produced by RiverObs.</p>
<p>In order to validate the estimates <span class="math inline">\(\hat{\sigma}_{st}\)</span>, we rely on analogous gdem-derived synthetic data that give, for our purposes, “true” values <span class="math inline">\(x^*_{st}\)</span>. Thus we can calculate a corresponding set of empirical errors <span class="math inline">\(\epsilon_{st}\)</span> for every location and time in the dataset. Since <span class="math inline">\(\epsilon_{st} = x_{st} - x^*_{st}\)</span>, then if our uncertainty estimates are correct (<span class="math inline">\(\hat{\sigma}_{x_{st}} = \sigma_{x_{st}}\)</span>), we obtain <span class="math inline">\(\sigma_{\epsilon_{st}} = \sigma_{x_{st}}= \hat{\sigma}_{x_{st}}\)</span>. A simple elementwise scaling, <span class="math inline">\(e_{st} \equiv \epsilon_{st} / \hat{\sigma}_{x_{st}}\)</span> therefore has <span class="math inline">\(\sigma_{e_{st}} = 1\)</span> for all <span class="math inline">\(s\)</span> and <span class="math inline">\(t\)</span>. (Recall that for any random variable <span class="math inline">\(Y\)</span> with mean <span class="math inline">\(\mu_Y\)</span> and variance <span class="math inline">\(\sigma^2_Y\)</span>, a linear transformation of the form <span class="math inline">\(W = aY + b\)</span> has mean <span class="math inline">\(\mu_W = a\mu_Y + b\)</span> and variance <span class="math inline">\(a^2\sigma_Y^2\)</span>. This is true regardless of distribution.)</p>
<p>Thus scaled, the errors <span class="math inline">\(e_{st}\)</span> can be compared across locations and times in order to validate the uncertainty estimates. A “good” model for <span class="math inline">\(\sigma_x\)</span> will result in a set of <span class="math inline">\(e_{st}\)</span> with empirical standard deviation that is close to 1. This observation leads directly to explicit tests for verifying the model responsible for producing <span class="math inline">\(\hat{\sigma}_{x_{st}}\)</span>.</p>
<div id="error-decomposition" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Error Decomposition</h3>
<p>Uncertainty can be parsed into two components–bias and variance, corresponding to “systematic” and “random” errors. Strictly speaking, if <span class="math inline">\(\sigma_x\)</span> is defined to be a standard deviation (square root of variance), then it does not include bias, and therefore ignores a potentially large component of uncertainty. Adjusting <span class="math inline">\(\hat{\sigma}_x\)</span> cannot remove this bias, but it can account for it by “lumping it in” to the variance. This choice of whether or not to account for bias leads to two separate sets of uncertainty validation–with and without bias-adjusting the scaled errors. Since the uncertainty estimates are produced using a method that explicitly assumes zero bias, it makes sense to validate these estimates without including bias. On the other hand, real-world errors will include both random and systematic components, and a true assessment of uncertainty should somehow measure how well uncertainty estimates account for the full error distribution–including bias.</p>
</div>
<div id="assumptions-of-normality" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Assumptions of Normality</h3>
<p>The uncertainty estimates <span class="math inline">\(\sigma_{x_{st}}\)</span> are provided without explicitly assuming a probability distribution for <span class="math inline">\(x\)</span> (or, equivalently, <span class="math inline">\(\epsilon\)</span>). However, explicit probabilistic tests for the truth of <span class="math inline">\(\sigma_{x}\)</span> are parametric, and rely on distributional assumptions, for example normality. The normality assumption is a reasonable one in the case of SWOT data, for at least two reasons. First, the feature-level measurements constitute aggregating (summing) over many independent radar “looks”, and as such will tend towards normality according to the central limit theorem. Second, the normal distribution has the property that it has the maximum <em>entropy</em>–colloquially, the maximum randomness–of any distribution for which all that is known is the mean and standard deviation. In SWOT data, that is the case: all that is reported is an estimate (<span class="math inline">\(x\)</span>) and a standard deviation (<span class="math inline">\(\sigma_x\)</span>). Thus, the normal distribution is a conservative choice; using any other distribution would unduly constrain the randomness it expresses.</p>
</div>
<div id="tests-for-validity-of-hatsigma_x" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Tests for validity of <span class="math inline">\(\hat{\sigma}_{x}\)</span></h3>
<div id="visual-checks" class="section level4">
<h4><span class="header-section-number">3.3.3.1</span> Visual Checks</h4>
<p>The scaled errors, <span class="math inline">\(e_{st}\)</span>, are expected to have standard deviation equal to 1 for all locations <span class="math inline">\(s\)</span> and times <span class="math inline">\(t\)</span>. Therefore, a histogram of <span class="math inline">\(e_{st}\)</span> should display most scaled errors between -1 and 1, and with a peak at 0 (if errors are unbiased and symmetrical). Other distribution plots (e.g. box and violin plots) should reveal the same. The stronger assumption of normality can be visually inspected using a histogram with a standard normal pdf superimposed; this should roughly match the (appropriately scaled) bars of the histogram. A normal quantile-quantile (QQ) plot checks the normality assumption more explicitly, and makes clear which parts of the distribution most strongly diverge from normality.</p>
<p>This rationale does not rule out selection of a more appropriate distribution based on empirical error distributions, rather the point is to justify the normal assumption a priori.</p>
</div>
<div id="qualitative-checks" class="section level4">
<h4><span class="header-section-number">3.3.3.2</span> Qualitative checks</h4>
<p>Descriptive statistics including the empirical standard deviation, RMSE, and percentiles of scaled errors can verify qualitatively the closeness of the observed to the theoretical error distribution. If the errors are unbiased and uncertainty estimates are correct, then both the RMSE and standard deviation should be approximately 1. Similarly, if we assume normally distributed errors then empirical quantiles should match theoretical–for example, the .025, .16, .5, .84, and .975 quantiles of <span class="math inline">\(e_{st}\)</span> should be approximately -1.96. -1, 0, 1, and 1.96, respectively. We do not expect these correspondences to be exact, only close enough to satisfy intuition.</p>
</div>
<div id="quantitative-hypothesis-test" class="section level4">
<h4><span class="header-section-number">3.3.3.3</span> Quantitative Hypothesis Test</h4>
<p>Assuming errors to be normally distributed, we can formulate an explicit hypothesis test for the following:</p>
<ul>
<li>Null hypothesis: <span class="math inline">\(\sigma_{e_{st}} = 1\)</span> for all <span class="math inline">\(s\)</span>, <span class="math inline">\(t\)</span>.</li>
<li>Alternative hypothesis: <span class="math inline">\(\sigma_{e_{st}} \ne 1\)</span> for some <span class="math inline">\(s\)</span> and/or <span class="math inline">\(t\)</span>.</li>
</ul>
<p>Under the null hypothesis, a test statistic of the form <span class="math inline">\(\chi^2 \equiv \sum_{s,t}(e_{st} - \bar{e})^2\)</span> has a chi-square distribution with degrees of freedom equal to the total number of data in the validation set minus 1.</p>
<p>Using a type-1 error rate of 0.05, the hypothesis test would reject the null hypothesis if the test statistic lies outside of the 0.025 - 0.975 quantile range of the chi-square distribution, and otherwise not reject the null hypothesis.</p>
<p>The same test could be modified to include the assumption that errors are unbiased, by removing the subtraction of <span class="math inline">\(\bar{e}\)</span> from the definition of <span class="math inline">\(\chi^2\)</span> above.</p>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="results.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
